{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanSym/Data-Science-Projects/blob/master/%5BML_Olympiad_Quality_Education_%5BEDA_e_Predi%C3%A7%C3%A3o_Baseline%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoplaB7FtIqu"
      },
      "source": [
        "# ML Olympiad - Quality Education"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alkyaWHa45T8"
      },
      "source": [
        "<center><img src=\"https://guiadoestudante.abril.com.br/wp-content/uploads/sites/4/2021/11/Provas.jpg\" alt=\"enem\" width=\"400\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYVVaNGot6G8"
      },
      "source": [
        "## Import das bibliotecas utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZscxbJDttIqy",
        "outputId": "158c2d4c-de13-45d1-df3c-e7e205a179a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geobr\n",
            "  Downloading geobr-0.2.0-py2.py3-none-any.whl (34 kB)\n",
            "Collecting geopandas<0.8.0,>=0.7.0 (from geobr)\n",
            "  Downloading geopandas-0.7.0-py2.py3-none-any.whl (928 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m928.1/928.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0,>=1.7.0 (from geobr)\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from geopandas<0.8.0,>=0.7.0->geobr) (1.5.3)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.10/dist-packages (from geopandas<0.8.0,>=0.7.0->geobr) (1.9.4.post1)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from geopandas<0.8.0,>=0.7.0->geobr) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->geopandas<0.8.0,>=0.7.0->geobr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->geopandas<0.8.0,>=0.7.0->geobr) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->geopandas<0.8.0,>=0.7.0->geobr) (1.22.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=2.2.0->geopandas<0.8.0,>=0.7.0->geobr) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona->geopandas<0.8.0,>=0.7.0->geobr) (23.1.0)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona->geopandas<0.8.0,>=0.7.0->geobr) (8.1.6)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona->geopandas<0.8.0,>=0.7.0->geobr) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona->geopandas<0.8.0,>=0.7.0->geobr) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona->geopandas<0.8.0,>=0.7.0->geobr) (1.16.0)\n",
            "Installing collected packages: shapely, geopandas, geobr\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.1\n",
            "    Uninstalling shapely-2.0.1:\n",
            "      Successfully uninstalled shapely-2.0.1\n",
            "  Attempting uninstall: geopandas\n",
            "    Found existing installation: geopandas 0.13.2\n",
            "    Uninstalling geopandas-0.13.2:\n",
            "      Successfully uninstalled geopandas-0.13.2\n",
            "Successfully installed geobr-0.2.0 geopandas-0.7.0 shapely-1.8.5.post1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pylab import rcParams\n",
        "from google.colab import drive\n",
        "from functools import reduce\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import gc\n",
        "\n",
        "# visualização de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "# coordenadas geográficas\n",
        "!pip install geobr\n",
        "import geopandas as gpd\n",
        "import geobr\n",
        "\n",
        "# drive do Google Colab\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Parâmetros\n",
        "plt.rcParams['figure.figsize'] = [8, 8]\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Filtra warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Plot de gráficos\n",
        "%matplotlib inline\n",
        "\n",
        "geobr.read_state(year = 2019)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfUAnGQKoTlP"
      },
      "source": [
        "### Variáveis Globais"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geobr"
      ],
      "metadata": {
        "id": "giKF2DFNKIJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtwzwHioW918"
      },
      "outputs": [],
      "source": [
        "# Divisão das Variaveis\n",
        "lista_targets = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
        "Variaveis_Socio_Economico = ['Q001','Q002',\t'Q003',\t'Q004',\t'Q005',\t'Q006',\t'Q007',\t'Q008',\t'Q009',\t'Q010',\t'Q011',\t'Q012',\t'Q013',\t'Q014',\t'Q015',\t'Q016',\t'Q017',\t'Q018',\t'Q019',\t'Q020',\t'Q021',\t'Q022',\t'Q023',\t'Q024',\t'Q025']\n",
        "Variaveis_Atendimento_Especializado = ['IN_BAIXA_VISAO',\t'IN_CEGUEIRA',\t'IN_SURDEZ',\t'IN_DEFICIENCIA_AUDITIVA',\t'IN_SURDO_CEGUEIRA',\t'IN_DEFICIENCIA_FISICA',\t'IN_DEFICIENCIA_MENTAL',\t'IN_DEFICIT_ATENCAO',\t'IN_DISLEXIA',\t'IN_DISCALCULIA',\t'IN_AUTISMO',\t'IN_VISAO_MONOCULAR',\t'IN_OUTRA_DEF']\n",
        "Variaveis_Cadastrais = ['NU_INSCRICAO',\t'CO_MUNICIPIO_RESIDENCIA',\t'NO_MUNICIPIO_RESIDENCIA',\t'CO_UF_RESIDENCIA',\t'SG_UF_RESIDENCIA',\t'NU_IDADE',\t'TP_SEXO',\t'TP_ESTADO_CIVIL',\t'TP_COR_RACA',\t'TP_NACIONALIDADE',\t'CO_MUNICIPIO_NASCIMENTO',\t'NO_MUNICIPIO_NASCIMENTO',\t'CO_UF_NASCIMENTO',\t'SG_UF_NASCIMENTO',\t'TP_ST_CONCLUSAO',\t'TP_ANO_CONCLUIU',\t'TP_ESCOLA',\t'TP_ENSINO',\t'IN_TREINEIRO']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuYc1_x0tIq0"
      },
      "source": [
        "## Métodos Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGOeRrBZtIq1"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\"\n",
        "    iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\n",
        "    fonte: https://www.kaggle.com/valleyzw/ubiquant-lgbm-baseline\n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in tqdm([x for x in df.columns if 'NU_NOTA_' not in x]):\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def show_missings(df):\n",
        "    '''\n",
        "    mostra porcentagem de missings no dataframe\n",
        "    '''\n",
        "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "    missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
        "                                     'percent_missing': percent_missing})\n",
        "\n",
        "    missing_value_df = missing_value_df.sort_values('percent_missing', ascending=False).round(2)\n",
        "    return (missing_value_df)\n",
        "\n",
        "\n",
        "def leitura_dados(path_train, path_test, sample_frac=-1):\n",
        "    '''\n",
        "    método para leitura dos datasets\n",
        "    '''\n",
        "    if sample_frac == -1:\n",
        "      df_desenv = reduce_mem_usage(pd.read_csv(path_train))\n",
        "    else:\n",
        "      df_desenv = reduce_mem_usage(pd.read_csv(path_train).sample(frac=sample_frac))\n",
        "    df_submit = reduce_mem_usage(pd.read_csv(path_test))\n",
        "    return (df_desenv, df_submit)\n",
        "\n",
        "\n",
        "def rmse_score(true, pred):\n",
        "    '''\n",
        "    rmse score\n",
        "    '''\n",
        "    return (sqrt(mean_squared_error(true, pred)))\n",
        "\n",
        "\n",
        "def map_cor_raca(cor_raca):\n",
        "    '''\n",
        "    mapeia cor/raca de acordo com o metadados fornecido\n",
        "    '''\n",
        "    if cor_raca == 0:\n",
        "        return 'Não informado'\n",
        "    elif cor_raca == 1:\n",
        "        return 'Branca'\n",
        "    elif cor_raca == 2:\n",
        "        return 'Preta'\n",
        "    elif cor_raca == 3:\n",
        "        return 'Parda'\n",
        "    elif cor_raca == 4:\n",
        "        return 'Amarela'\n",
        "    elif cor_raca == 5:\n",
        "        return 'Indígena'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "\n",
        "def map_estado_civil(estado_civil):\n",
        "    '''\n",
        "    mapeia estado civil de acordo com o metadados fornecido\n",
        "    '''\n",
        "    if estado_civil == 0:\n",
        "        return 'Não informado'\n",
        "    elif estado_civil == 1:\n",
        "        return 'Solteiro(a)'\n",
        "    elif estado_civil == 2:\n",
        "        return 'Casado(a)/Mora com companheiro(a)'\n",
        "    elif estado_civil == 3:\n",
        "        return 'Divorciado(a)/Desquitado(a)/Separado(a)'\n",
        "    elif estado_civil == 4:\n",
        "        return 'Viúvo(a)'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "\n",
        "def gerar_painel_barra(data_frame,\n",
        "                      var,\n",
        "                      hue,\n",
        "                      title = '',\n",
        "                      title_subplot_1 = '',\n",
        "                      title_subplot_2 = '',\n",
        "                      legend_subplot_2 = '',\n",
        "                      xlabel = 'Quantidade',\n",
        "                      ylabel = '',\n",
        "                      figsize = (12, 6)\n",
        "                      ):\n",
        "  '''\n",
        "  gera gráfico de barras\n",
        "  '''\n",
        "  fig, ax = plt.subplots(1, 2, figsize = figsize)\n",
        "  sns.countplot(data = data_frame,\n",
        "                y = var,\n",
        "                ax = ax[0])\n",
        "  sns.countplot(data = data_frame,\n",
        "                y = var,\n",
        "                hue = hue,\n",
        "                ax = ax[1])\n",
        "  ax[0].set(ylabel = ylabel, xlabel = xlabel, title = title_subplot_1)\n",
        "  ax[1].set(ylabel = ylabel, xlabel = xlabel, title = title_subplot_2)\n",
        "  ax[1].legend(title = legend_subplot_2)\n",
        "  fig.suptitle(title)\n",
        "  fig.tight_layout(pad = 4)\n",
        "\n",
        "\n",
        "def print_importancias_lasso(df, coef):\n",
        "  '''\n",
        "  importância das variáveis explicativas do modelo lasso\n",
        "  '''\n",
        "  for e in sorted (list(zip(list(df), coef)), key = lambda e: -abs(e[1])):\n",
        "    if e[1] != 0:\n",
        "      print('\\t{}, {:.3f}'.format(e[0], e[1]))\n",
        "\n",
        "\n",
        "def percentile(n):\n",
        "    '''\n",
        "    retorna percentil\n",
        "    '''\n",
        "    def percentile_(x):\n",
        "        return x.quantile(n)\n",
        "    percentile_.__name__ = 'percentile_{:2.0f}'.format(n*100)\n",
        "    return percentile_\n",
        "\n",
        "\n",
        "def estatistica_descritiva_por_estado(df, metrica, localizacao_estado = geobr.read_state(year = 2019)):\n",
        "  \"Calcula alguma estatística descritiva para as notas do Enem por estado.\"\n",
        "  # provas do dataset de base\n",
        "  provas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
        "  # obtém os resultados por estado conforme medida estatística inserida\n",
        "  df = df.groupby(by = 'SG_UF_RESIDENCIA', as_index = False)[provas].agg(metrica)\n",
        "  # geolocalização\n",
        "  df = gpd.GeoDataFrame(pd.merge(\n",
        "    df,\n",
        "    localizacao_estado,\n",
        "    left_on = 'SG_UF_RESIDENCIA',\n",
        "    right_on = 'abbrev_state',\n",
        "    how = 'inner'))\n",
        "\n",
        "  return df\n",
        "\n",
        "def plot_mapa_estado(df, estatistica_descritiva = np.mean, title = '', cmap = 'BuPu'):\n",
        "  '''\n",
        "  gera mapa heatmap para o Brasil populado com a estatística descritiva de interesse\n",
        "  '''\n",
        "  # cria o DataFrame conforme estatística descritiva definida\n",
        "  df = estatistica_descritiva_por_estado(df=df, metrica = estatistica_descritiva)\n",
        "  # labels para o pllot\n",
        "  labels_provas = ['Ciências da Natureza', 'Ciências Humanas', 'Linguagens', 'Matemática', 'Redação']\n",
        "  # colunas referentes a prova\n",
        "  provas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
        "  # cria a figura\n",
        "  fig, ax = plt.subplots(1, 5, figsize = (20, 20))\n",
        "  # itera na lista de provas e cria o mapa\n",
        "  for index, prova in enumerate(provas):\n",
        "    df.plot(\n",
        "        column = prova,\n",
        "        cmap = cmap,\n",
        "        edgecolor = 'lightgray',\n",
        "        lw = 0.3,\n",
        "        ax = ax[index],\n",
        "        legend=True,\n",
        "        legend_kwds = {'shrink': 0.08}\n",
        "        )\n",
        "    # remove marcações dos eixos\n",
        "    ax[index].axis('off')\n",
        "    # labels\n",
        "    ax[index].set_title(labels_provas[index], fontsize  = 10)\n",
        "\n",
        "  fig.suptitle(title, y = 0.6 , weight = 'bold')\n",
        "  fig.tight_layout(pad = 2);\n",
        "\n",
        "\n",
        "def Gerar_Grafico_Economico(Coluna):\n",
        "  '''\n",
        "  Função para gerar gráfico socio economico\n",
        "  '''\n",
        "\n",
        "  # Posicao\n",
        "  Posicao_Index = 1\n",
        "\n",
        "  # Ordenando os dados\n",
        "  Filtro = Analise_Econominca.sort_values(by=str(Coluna))\n",
        "\n",
        "  # Tamanho da Imagem\n",
        "  fig, ax = plt.subplots(figsize=(18, 15))\n",
        "\n",
        "  # Cor de fundo\n",
        "  Cor_Fundo = \"#F5F4EF\"\n",
        "  ax.set_facecolor(Cor_Fundo)\n",
        "  fig.set_facecolor(Cor_Fundo)\n",
        "\n",
        "  # Paleta de Cores\n",
        "  Paleta_Cores = sns.color_palette('flare', 7)\n",
        "\n",
        "  # Estilo do gráfico\n",
        "  plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "  # Incluindo o Titulo na Figura\n",
        "  plt.suptitle(f'Dados do Questionário Socieconômico | {Coluna}',\n",
        "             fontsize=22, color='#404040', fontfamily='KyivType Sans', fontweight=600 )\n",
        "\n",
        "  # Loop plotar os gráficos\n",
        "  for Grafico in Analise_Econominca[lista_targets]:\n",
        "\n",
        "    # Retiando qlq valor zerado\n",
        "    Filtro = Filtro.loc[ Filtro[Grafico] > 0 ]\n",
        "\n",
        "    # Posição do Plot\n",
        "    plt.subplot( 5, 1, Posicao_Index )\n",
        "\n",
        "    # Plot\n",
        "    sns.boxplot( data=Filtro, x=str(Coluna), y=Grafico, showmeans = True, linewidth=1, width=0.4, color=Paleta_Cores[Posicao_Index] )\n",
        "    sns.stripplot( data=Filtro, x=str(Coluna), y=Grafico, size=0.3, color='0.1', linewidth=0 )\n",
        "\n",
        "    # Titulo\n",
        "    plt.title(f'Análise {Grafico}', loc='left', fontsize=14, fontweight=200)\n",
        "\n",
        "    # Labels\n",
        "    plt.ylabel('Nota de 0 - 1000')\n",
        "    plt.xlabel('Resposta dos participantes')\n",
        "\n",
        "    # Ajustando distancias dos gráficos no relatorio\n",
        "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.94, wspace=0.2, hspace=0.25);\n",
        "\n",
        "    # Troca index do Gráfico\n",
        "    Posicao_Index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlu6udautIq2"
      },
      "source": [
        "## Leitura de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNHHKneXtIq3"
      },
      "source": [
        "##### Dataset de desenvolvimento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoLFUvHDtIq4"
      },
      "outputs": [],
      "source": [
        "path_input_train='/content/gdrive/MyDrive/ML_Olympiad_Kaggle/train.csv'\n",
        "path_input_test='/content/gdrive/MyDrive/ML_Olympiad_Kaggle/test.csv'\n",
        "path_output_submission='/content/gdrive/MyDrive/ML_Olympiad_Kaggle/df_submit_baseline.csv'\n",
        "\n",
        "df_desenv, df_submit = leitura_dados(path_input_train, path_input_test, sample_frac=0.1)\n",
        "print (df_desenv.shape, df_submit.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVlQ5_xntIq5"
      },
      "outputs": [],
      "source": [
        "df_desenv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RmP_xXqtIq5"
      },
      "outputs": [],
      "source": [
        "df_submit.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M329znaktIq6"
      },
      "source": [
        "## Análise Exploratória de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0A25o8LtIq6"
      },
      "outputs": [],
      "source": [
        "# descritivo das variáveis do dataset\n",
        "df_desenv.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTj7mfH2wrG2"
      },
      "outputs": [],
      "source": [
        "df_desenv.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oiora5TctIq7"
      },
      "outputs": [],
      "source": [
        "# tipo das variáveis do dataset\n",
        "df_desenv.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLZImXSGtIq7"
      },
      "outputs": [],
      "source": [
        "# lista de variáveis do dataset\n",
        "df_desenv.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJTE5x2otIq7"
      },
      "outputs": [],
      "source": [
        "# colunas do target\n",
        "df_desenv[lista_targets].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "435uQJJ1tIq8"
      },
      "outputs": [],
      "source": [
        "# porcentagem de dados faltantes (missings) no dataset\n",
        "show_missings(df_desenv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UklMCz4_w2AM"
      },
      "outputs": [],
      "source": [
        "# quantidade de valores únicos em cada coluna\n",
        "df_desenv.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgk0Aj55a1Da"
      },
      "outputs": [],
      "source": [
        "# frequência dos inscritos no Enem por UF\n",
        "# Através das análises, é possível observar que a maioria dos inscritos é de São Paulo (16%), seguido de Minas Gerais (10,5%) e Bahia (7,7%)\n",
        "df_desenv['SG_UF_RESIDENCIA'].value_counts(dropna=False, ascending=False, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0t2P-NHa9Cp"
      },
      "outputs": [],
      "source": [
        "# Correlação entre as notas das provas do Enem\n",
        "fig, ax = plt.subplots()\n",
        "corr_provas = df_desenv[lista_targets].corr()\n",
        "sns.heatmap(corr_provas, annot=True, cmap = 'Blues', ax = ax);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMBUSs5zocdU"
      },
      "source": [
        "### Análises Visuais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WD6Fi9YY7Y7"
      },
      "outputs": [],
      "source": [
        "# Boxplot das notas do Enem\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "sns.boxplot(data = df_desenv[lista_targets], ax = ax);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAxmqEqYY_L7"
      },
      "outputs": [],
      "source": [
        "# Analisando Residencia x Notas\n",
        "Analise_Target = df_desenv[['SG_UF_RESIDENCIA', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']]\n",
        "\n",
        "# Criando o relátorio\n",
        "fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
        "\n",
        "# Plotando as notas em histogramas\n",
        "sns.histplot(data=Analise_Target, x='NU_NOTA_CN', color='skyblue', bins=100, ax=axs[0, 0])\n",
        "sns.histplot(data=Analise_Target, x='NU_NOTA_CH', color='olive', bins=100, ax=axs[0, 1])\n",
        "sns.histplot(data=Analise_Target, x='NU_NOTA_LC', color='gold', bins=100, ax=axs[1, 0])\n",
        "sns.histplot(data=Analise_Target, x='NU_NOTA_MT', color='teal', bins=100, ax=axs[1, 1])\n",
        "sns.histplot(data=Analise_Target, x='NU_NOTA_REDACAO', color='olive', bins=50, ax=axs[2, 0])\n",
        "axs[2, 1].set_axis_off()\n",
        "\n",
        "# Incluindo o Titulo na Figura\n",
        "plt.suptitle('Distribuição das notas para cada prova', fontsize=22, color='#404040', fontweight=600);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHEqzvPIQCGF"
      },
      "outputs": [],
      "source": [
        "print ('Idade média:', round(df_desenv['NU_IDADE'].mean(), 2))\n",
        "print ('Idade mediana:', round(df_desenv['NU_IDADE'].median(), 2))\n",
        "print ('Idade mais frequente (moda):', round(df_desenv['NU_IDADE'].mode()[0], 2))\n",
        "plt.hist(df_desenv['NU_IDADE'], bins=50);\n",
        "plt.title('Perfil etário dos inscritos no Enem');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf6pcrTfP5cu"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='TP_SEXO', data=df_desenv)\n",
        "plt.title('Distribuição de Gênero dos inscritos');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdUTcE5DP5fm"
      },
      "outputs": [],
      "source": [
        "df_desenv['MAP_TP_COR_RACA'] = df_desenv['TP_COR_RACA'].apply(map_cor_raca)\n",
        "gerar_painel_barra(df_desenv, 'MAP_TP_COR_RACA', 'TP_SEXO',\n",
        "                   title = 'Perfil de cor e raça dos inscritos',\n",
        "                   title_subplot_1 = 'Cor/raça',\n",
        "                   title_subplot_2 = 'Cor/raça por gênero',\n",
        "                   legend_subplot_2 = 'Gênero',\n",
        "                   ylabel = 'Cor/raça')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PllgfBhQTj9k"
      },
      "outputs": [],
      "source": [
        "df_desenv['MAP_TP_ESTADO_CIVIL'] = df_desenv['TP_ESTADO_CIVIL'].apply(map_estado_civil)\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize = (12, 6))\n",
        "sns.countplot(data = df_desenv,\n",
        "             y = 'MAP_TP_ESTADO_CIVIL', ax = ax[0])\n",
        "sns.countplot(data = df_desenv,\n",
        "             y = 'MAP_TP_ESTADO_CIVIL', hue = 'TP_SEXO', ax = ax[1])\n",
        "ax[0].set(ylabel = 'Estado Civil', xlabel = 'Quantidade',title = 'Estado civil')\n",
        "ax[1].set(ylabel = 'Estado Civil', xlabel = 'Quantidade',title = 'Estado civil por gênero')\n",
        "ax[1].legend(title = 'Gênero')\n",
        "fig.suptitle('Estado civil dos inscritos')\n",
        "fig.tight_layout(pad = 4);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6VJlMMVuycT"
      },
      "outputs": [],
      "source": [
        "# Calcula a quantidade de inscritos em cada estado (amostra)\n",
        "# Através dessa análise, podemos concluir que a maria dos inscritos é de São Paulo\n",
        "df_inscritos_por_estado = df_desenv.groupby(by = 'SG_UF_RESIDENCIA')[['SG_UF_RESIDENCIA']].count()\\\n",
        ".rename(columns = {'SG_UF_RESIDENCIA': 'quantidade_inscritos'})\\\n",
        ".reset_index()\\\n",
        ".sort_values(by = 'quantidade_inscritos', ascending = False)\n",
        "\n",
        "# inscritos por estado com geolocalização\n",
        "df_inscritos_por_estado_spatial_data = gpd.GeoDataFrame(pd.merge(\n",
        "    df_inscritos_por_estado,\n",
        "    geobr.read_state(year = 2019),\n",
        "    left_on = 'SG_UF_RESIDENCIA',\n",
        "    right_on = 'abbrev_state',\n",
        "    how = 'inner'\n",
        "))\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 8))\n",
        "df_inscritos_por_estado_spatial_data.plot(\n",
        "    column = 'quantidade_inscritos',\n",
        "    cmap = 'Blues',\n",
        "    legend = True,\n",
        "    legend_kwds= {\n",
        "        \"label\": \"Quantidade de inscritos\",\n",
        "        \"orientation\": \"horizontal\",\n",
        "        \"shrink\": 0.4,\n",
        "    },\n",
        "    edgecolor = 'lightgray',\n",
        "    lw = 0.3,\n",
        "    ax = ax\n",
        ")\n",
        "\n",
        "ax.set_title('Quantidade de inscritos no Enem por estado')\n",
        "ax.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MP3efCOvJvu"
      },
      "outputs": [],
      "source": [
        "# Calcula a nota média de cada prova por estado\n",
        "# Através dessa análise, podemos concluir as regiões Sul e Sudeste possuem as maiores notas médias, e a região Norte as menores\n",
        "plot_mapa_estado(df_desenv, np.mean, 'Média das notas por estado', 'hot_r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BHhYP6avYET"
      },
      "outputs": [],
      "source": [
        "# Calcula a nota percentil 99 de cada prova por estado\n",
        "# Através dessa análise, podemos concluir a região Sudeste possuem as maiores notas do percentil 99, e a região Norte as menores\n",
        "plot_mapa_estado(df_desenv, percentile(0.99), 'Percentil 99 das notas por estado', 'hot_r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o85rQqUcvJ2U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dD_KEkFQvOt"
      },
      "outputs": [],
      "source": [
        "print('Até que série seu pai, ou o homem responsável por você, estudou? \\n')\n",
        "Analise_Econominca = df_desenv[Variaveis_Socio_Economico + lista_targets]\n",
        "Gerar_Grafico_Economico('Q001')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5JldUPkR-B7"
      },
      "outputs": [],
      "source": [
        "print('Até que série sua mãe, ou a mulher responsável por você, estudou? \\n')\n",
        "Gerar_Grafico_Economico('Q002')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-LUEhfrR-EA"
      },
      "outputs": [],
      "source": [
        "print('A partir da apresentação de algumas ocupações divididas em grupos ordenados, indique o grupo que contempla a ocupação mais próxima da ocupação do seu pai ou do homem responsável por você. (Se ele não estiver trabalhando, escolha uma ocupação pensando no último trabalho dele). \\n')\n",
        "Gerar_Grafico_Economico('Q003')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na3RornySDAO"
      },
      "outputs": [],
      "source": [
        "print('A partir da apresentação de algumas ocupações divididas em grupos ordenados, \\n indique o grupo que contempla a ocupação mais próxima da ocupação da sua mãe ou da mulher responsável por você. (Se ela não estiver trabalhando, \\n escolha uma ocupação pensando no último trabalho dela). \\n')\n",
        "Gerar_Grafico_Economico('Q004')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyzfnP1iSDDo"
      },
      "outputs": [],
      "source": [
        "print('Incluindo você, quantas pessoas moram atualmente em sua residência? \\n')\n",
        "Gerar_Grafico_Economico('Q005')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nPKD4ZSSDFH"
      },
      "outputs": [],
      "source": [
        "print('Qual é a renda mensal de sua família? (Some a sua renda com a dos seus familiares.) \\n')\n",
        "Gerar_Grafico_Economico('Q006')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Fh4N-qQvR2"
      },
      "outputs": [],
      "source": [
        "# Analisando Residência x Notas na prova do Enem\n",
        "Analise_UF = df_desenv[['SG_UF_RESIDENCIA', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']]\n",
        "\n",
        "# Tamanho da Imagem\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "\n",
        "# Cor de fundo\n",
        "Cor_Fundo = \"#F5F4EF\"\n",
        "ax.set_facecolor(Cor_Fundo)\n",
        "fig.set_facecolor(Cor_Fundo)\n",
        "\n",
        "# Estilo do gráfico\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "# Posição do Plot\n",
        "plt.subplot(2, 1, 1)\n",
        "\n",
        "# Plot\n",
        "plt.plot(Analise_UF.groupby( by='SG_UF_RESIDENCIA').median(), linewidth=4, alpha=0.7)\n",
        "\n",
        "# Titulo\n",
        "plt.title('Mediana das provas por Estado', loc='left', fontsize=14, fontweight=0)\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Estados', fontsize=14 )\n",
        "plt.ylabel('Nota de 0 - 1000', fontsize=14)\n",
        "\n",
        "# Legenda\n",
        "plt.legend( ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'],\n",
        "           ncol=5, fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.1), shadow=True )\n",
        "\n",
        "# Posição do Plot\n",
        "plt.subplot( 2, 1, 2 )\n",
        "\n",
        "# Plot\n",
        "plt.plot( Analise_UF.groupby( by='SG_UF_RESIDENCIA').mean(), linewidth=4, alpha=0.7 )\n",
        "\n",
        "# Titulo\n",
        "plt.title('Média das provas por Estado', loc='left', fontsize=14, fontweight=0)\n",
        "\n",
        "# Labels\n",
        "plt.xlabel('Estados', fontsize=14)\n",
        "plt.ylabel('Nota de 0 - 1000', fontsize=14)\n",
        "\n",
        "# Legenda\n",
        "plt.legend( ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'],\n",
        "           ncol=5, fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.1), shadow=True )\n",
        "\n",
        "# Ajustando distancias dos gráficos no relatorio\n",
        "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.91, wspace=0.2, hspace=0.4)\n",
        "\n",
        "# Incluindo o Titulo na Figura\n",
        "plt.suptitle('Média/Media por Estado do participante',\n",
        "             fontsize=22, color='#404040', fontfamily='KyivType Sans', fontweight=600 );"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5ZZAxDFQvUU"
      },
      "outputs": [],
      "source": [
        "# Tamanho da Imagem\n",
        "fig, ax = plt.subplots(figsize=(20, 25))\n",
        "\n",
        "# Cor de fundo\n",
        "Cor_Fundo = \"#F5F4EF\"\n",
        "ax.set_facecolor(Cor_Fundo)\n",
        "fig.set_facecolor(Cor_Fundo)\n",
        "\n",
        "# Estilo do gráfico\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "# Lista de Paletas de Cores\n",
        "Paleta_Cores = sns.color_palette('flare', 30)\n",
        "\n",
        "# Dimensão do relatório\n",
        "Quantidade_Linhas = round (Analise_UF['SG_UF_RESIDENCIA'].nunique() / 4 ) + 1\n",
        "Colunas = 4\n",
        "\n",
        "# Loop para criar o gráfico\n",
        "for Posicao, Estado in enumerate( sorted( list( Analise_UF['SG_UF_RESIDENCIA'].unique() ) ) + list(['Geral']) ):\n",
        "\n",
        "    # Pisção do GRáfico\n",
        "    plt.subplot( Quantidade_Linhas, Colunas, Posicao + 1 )\n",
        "\n",
        "    # Condição\n",
        "    if Estado != 'Geral':\n",
        "        # Filtro do Estado\n",
        "        Nota_Matematica = Analise_UF.loc[\n",
        "            ( Analise_UF['SG_UF_RESIDENCIA'] == Estado ) & ( Analise_UF['NU_NOTA_MT'] > 0 ) ]['NU_NOTA_MT']\n",
        "\n",
        "        # Titulo do gráfico\n",
        "        plt.title(f'Nota de Matemática do Estado: {Estado}', loc='left', fontsize=14, fontweight=100 )\n",
        "\n",
        "    else:\n",
        "        # Filtro para todos Estados\n",
        "        Nota_Matematica = Analise_UF.loc[ ( Analise_UF['NU_NOTA_MT'] > 0 ) ]['NU_NOTA_MT']\n",
        "\n",
        "        # Titulo do gráfico\n",
        "        plt.title(f'Nota de Matemática nível Brasil', loc='left', fontsize=14, fontweight=100 )\n",
        "\n",
        "    # Plot do Boxplot\n",
        "    sns.boxplot( Nota_Matematica,\n",
        "                saturation = 0.55,\n",
        "                color = Paleta_Cores[Posicao],\n",
        "                showmeans = True,\n",
        "                linewidth=1,\n",
        "                width=0.5,\n",
        "                meanprops = {'markerfacecolor':'green', 'markeredgecolor':'white', 'markersize':'8'} )\n",
        "\n",
        "    # Anotação em cada gráficos\n",
        "    plt.annotate(\n",
        "        f'Média:{ round(Nota_Matematica.mean()) }',\n",
        "        xy = (1.0, -0.18),\n",
        "        xycoords='axes fraction',\n",
        "        ha = 'right',\n",
        "        va = 'center',\n",
        "        color='green',\n",
        "        fontsize=12,\n",
        "        bbox = dict( facecolor=\"#fff\", edgecolor=\"#009000\", boxstyle=\"round\", pad=0.25 ),\n",
        "        fontweight=500 )\n",
        "\n",
        "    # Labels\n",
        "    plt.xlabel('Nota de 0 - 1000')\n",
        "    plt.ylabel('Distribuição das Notas')\n",
        "\n",
        "    # Ajuste da escala\n",
        "    plt.xlim(0, 1000)\n",
        "\n",
        "# Ajustando espaços entre os gráficos\n",
        "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.94, wspace=0.2, hspace=0.45)\n",
        "\n",
        "# Incluindo o Titulo na Figura\n",
        "plt.suptitle('Análise nota de Matemática por Estado - Exame Nacional do Ensino Médio (Enem)',\n",
        "             fontsize=22,\n",
        "             color='#404040',\n",
        "             fontfamily='KyivType Sans',\n",
        "             fontweight=600 );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sR37FahYymr"
      },
      "source": [
        "### Testes de Hipótese"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfN71cVHYwtW"
      },
      "outputs": [],
      "source": [
        "# Análise da cor de pele: brancos e pretos\n",
        "# Através dessa análise é possível observar como são diferentes as notas para pessoas de cor branca e preta\n",
        "# Pessoas de cor branca possuem notas maiores do que pessoas pretas, tanto na média quanto no percentil 99\n",
        "brancos = df_desenv.query(\"TP_COR_RACA == 1 and NU_NOTA_MT == NU_NOTA_MT\")['NU_NOTA_MT']\n",
        "pretos = df_desenv.query(\"TP_COR_RACA == 2 and NU_NOTA_MT == NU_NOTA_MT\")['NU_NOTA_MT']\n",
        "\n",
        "print (f'Nota média em matemática de inscritos brancos: {round(brancos.mean(), 2)}')\n",
        "print (f'Nota média em matemática de inscritos pretos: {round(pretos.mean(), 2)}')\n",
        "print (f'Percentil 99 da nota em matemática de inscritos brancos: {round(np.quantile(brancos, 0.99), 2)}')\n",
        "print (f'Percentil 99 da nota em matemática de inscritos pretos: {round(np.quantile(pretos, 0.99), 2)}')\n",
        "\n",
        "plt.hist(brancos, bins=30, label='Branco', histtype='stepfilled', color='green')\n",
        "plt.hist(pretos, bins=30, label='Preto', alpha=.7, histtype='stepfilled', color='red')\n",
        "plt.xlabel('Nota em Matemática')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.axvline(x=brancos.mean(), color='limegreen')\n",
        "plt.axvline(x=pretos.mean(), color='darkred')\n",
        "plt.title('Distribuição das notas de Matemática dos inscritos brancos e pretos')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot das notas de Matemática de brancos e pretos\n",
        "dict_notas = {'brancos': brancos.values.tolist(),\n",
        "              'pretos': pretos.values.tolist()}\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "ax.boxplot(dict_notas.values())\n",
        "ax.set_xticklabels(dict_notas.keys())\n",
        "plt.title('Boxplot das notas de Matemática dos inscritos brancos e pretos')\n",
        "plt.show()\n",
        "\n",
        "# Teste de hipótese\n",
        "# Como o p-valor é de 0, devemos rejeitar a hipótese nula (de que não existe correlação entre a cor do inscrito e a sua nota de Matemática no Enem)\n",
        "# Desse modo, é possível concluir que a cor está correlacionada com a nota de Matemática do Enem\n",
        "stats.ks_2samp(brancos, pretos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qo78QO9wX6u"
      },
      "outputs": [],
      "source": [
        "# Análise da nota de matemática de inscritos treineiros e não treineiros\n",
        "# Através dessa análise é possível observar como são diferentes as notas para treineiros e não treineiros\n",
        "# Curiosamente, treineiros possuem uma nota média maior do que não treineiros,\n",
        "# mas a nota percentil 99 dos não treineiros é muito superior à nota dos treineiros\n",
        "treineiros = df_desenv.query(\"IN_TREINEIRO == 1 and NU_NOTA_MT == NU_NOTA_MT\")['NU_NOTA_MT']\n",
        "nao_treineiros = df_desenv.query(\"IN_TREINEIRO == 0 and NU_NOTA_MT == NU_NOTA_MT\")['NU_NOTA_MT']\n",
        "\n",
        "print (f'Nota média em matemática de inscritos treineiros: {round(treineiros.mean(), 2)}')\n",
        "print (f'Nota média em matemática de inscritos não treineiros: {round(nao_treineiros.mean(), 2)}')\n",
        "print (f'Percentil 99 da nota em matemática de inscritos treineiros: {round(np.quantile(treineiros, 0.99), 2)}')\n",
        "print (f'Percentil 99 da nota em matemática de inscritos não treineiros: {round(np.quantile(nao_treineiros, 0.99), 2)}')\n",
        "\n",
        "plt.hist(treineiros, bins=30, label='Treineiro', histtype='stepfilled', color='green')\n",
        "plt.hist(nao_treineiros, bins=30, label='Não Treineiro', alpha=.7, histtype='stepfilled', color='red')\n",
        "plt.xlabel('Nota em Matemática')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.axvline(x=treineiros.mean(), color='limegreen')\n",
        "plt.axvline(x=nao_treineiros.mean(), color='darkred')\n",
        "plt.title('Distribuição das notas de Matemática dos inscritos treineiros e não treineiros')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot das notas de Matemática de treineiros e não treineiros\n",
        "dict_notas = {'treineiros': treineiros.values.tolist(),\n",
        "              'nao_treineiros': nao_treineiros.values.tolist()}\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "ax.boxplot(dict_notas.values())\n",
        "ax.set_xticklabels(dict_notas.keys())\n",
        "plt.title('Boxplot das notas de Matemática dos inscritos treineiros e não treineiros')\n",
        "plt.show()\n",
        "\n",
        "# Teste de hipótese\n",
        "# Como o p-valor é próximo de 0, devemos rejeitar a hipótese nula (de que não existe correlação entre ser ou não treineiro na nota de Matemática no Enem)\n",
        "# Desse modo, é possível concluir que o fato do inscrito ser treineiro está correlacionado com a sua nota de Matemática do Enem\n",
        "stats.ks_2samp(treineiros, nao_treineiros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9RG5-49tIrA"
      },
      "source": [
        "## Modelagem\n",
        "Nesta etapa é realizada a modelagem preditiva da nota das 5 provas utilizando a técnica Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MruPi0uU1aYK"
      },
      "outputs": [],
      "source": [
        "# lista de variáveis explicativas para utilizar no modelo\n",
        "lista_vars_explicativas = ['Q024', 'Q005_map', 'IDH_UF_RESIDENCIA', 'IN_ACESSO', 'Q006_map',\n",
        "                           'TP_ANO_CONCLUIU', 'TP_LINGUA', 'TP_DEPENDENCIA_ADM_ESC', 'Q006',\n",
        "                           'NU_IDADE', 'Q002', 'Q003', 'TP_SEXO', 'CO_ESCOLA', 'CO_MUNICIPIO_PROVA',\n",
        "                           'Q001', 'Q004', 'TP_ESCOLA', 'TP_STATUS_REDACAO', 'TP_COR_RACA', 'Q005',\n",
        "                           'SG_UF_NASCIMENTO', 'ANALFABETISMO_UF_RESIDENCIA', 'NO_MUNICIPIO_NASCIMENTO',\n",
        "                           'NO_MUNICIPIO_RESIDENCIA', 'Q008', 'TP_ENSINO', 'Q013', 'SG_UF_PROVA',\n",
        "                           'NO_MUNICIPIO_PROVA', 'TP_ST_CONCLUSAO', 'Q022', 'Q019', 'Q021', 'IN_LIBRAS',\n",
        "                           'TP_ESTADO_CIVIL', 'Q007', 'TP_NACIONALIDADE', 'IN_SEM_RECURSO', 'Q025', 'IN_SALA_ESPECIAL',\n",
        "                           'POP_UF_RESIDENCIA', 'Q011', 'Q010', 'Q015', 'Q014', 'Q018', 'SG_UF_ESC',\n",
        "                           'Q016', 'IN_TREINEIRO', 'Q012', 'Q009', 'IN_DEFICIT_ATENCAO', 'TP_SIT_FUNC_ESC',\n",
        "                           'NO_MUNICIPIO_ESC', 'IN_LEDOR', 'CO_MUNICIPIO_ESC', 'Q017', 'IN_TEMPO_ADICIONAL',\n",
        "                           'IN_DEFICIENCIA_AUDITIVA', 'TP_LOCALIZACAO_ESC', 'Q023', 'IN_DEFICIENCIA_MENTAL',\n",
        "                           'IN_SURDEZ', 'Q020', 'IN_AUTISMO', 'IN_DEFICIENCIA_FISICA', 'IN_TRANSCRICAO',\n",
        "                           'TP_PRESENCA_MT', 'TP_PRESENCA_LC', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH',\n",
        "                           'Mmam2031', 'Mmam13', 'Mreh0113', 'Analfabetismo1', 'Rendimento',\n",
        "                           'IFDM_2006', 'IFDM_2007', 'IFDM_2008', 'IFDM_2009', 'IFDM_2010', 'VR_IDHM',\n",
        "                           'VR_IDHM_RENDA', 'VR_IDHM_EDU', 'VR_IDHM_LONG']\n",
        "\n",
        "\n",
        "lista_df_submissao = []\n",
        "lista_erros_treino = []\n",
        "lista_erros_teste = []\n",
        "\n",
        "# faz um modelo por target (nota da prova)\n",
        "for target in lista_targets:\n",
        "    print ('***************')\n",
        "    print (target)\n",
        "    print ('***************')\n",
        "\n",
        "    # Separa dados em treino (80%) e teste (20%) - Hold out split\n",
        "    df_train, df_test = train_test_split(df_desenv, test_size=0.2, random_state=42)\n",
        "\n",
        "    # treino\n",
        "    X_train = df_train[lista_vars_explicativas]\n",
        "    y_train = df_train[target].copy()\n",
        "\n",
        "    # teste\n",
        "    X_test = df_test[lista_vars_explicativas]\n",
        "    y_test = df_test[target].copy()\n",
        "\n",
        "    # submit\n",
        "    X_submit = df_submit[lista_vars_explicativas]\n",
        "\n",
        "    # Lebel Encoder\n",
        "    for coluna in X_train.columns.tolist():\n",
        "      if (X_train[coluna].dtype != int and X_train[coluna].dtype != float):\n",
        "        labelencoder = LabelEncoder()\n",
        "        labelencoder.fit_transform(pd.concat([X_train[coluna], X_test[coluna], X_submit[coluna]], axis=0))\n",
        "        X_train[coluna] = labelencoder.transform(X_train[coluna])\n",
        "        X_test[coluna] = labelencoder.transform(X_test[coluna])\n",
        "        X_submit[coluna] = labelencoder.transform(X_submit[coluna])\n",
        "\n",
        "    # Remove valores missing\n",
        "    X_train = X_train.fillna(-999)\n",
        "    X_test = X_test.fillna(-999)\n",
        "    X_submit = X_submit.fillna(-999)\n",
        "\n",
        "    # Ignora notas missing\n",
        "    y_train = y_train.fillna(0)\n",
        "    y_test = y_test.fillna(0)\n",
        "\n",
        "    #########\n",
        "    # Lasso #\n",
        "    #########\n",
        "\n",
        "    clf = Lasso(alpha=1.0, max_iter = 10000)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # importâncias das variáveis explicativas\n",
        "    print_importancias_lasso(X_train, clf.coef_)\n",
        "\n",
        "    # Erro de treino\n",
        "    y_pred = clf.predict(X_train)\n",
        "    erro = rmse_score(y_train, y_pred)\n",
        "    print ('Erro de treino:', erro)\n",
        "    lista_erros_treino.append(erro)\n",
        "\n",
        "    # Erro de teste\n",
        "    y_pred = clf.predict(X_test)\n",
        "    erro = rmse_score(y_test, y_pred)\n",
        "    print ('Erro de teste:', erro)\n",
        "    lista_erros_teste.append(erro)\n",
        "\n",
        "    # Previsão para o dataset de submissão\n",
        "    df_submit_results = df_submit[['NU_INSCRICAO']].copy()\n",
        "    df_submit_results[target] = clf.predict(X_submit)\n",
        "    lista_df_submissao.append(df_submit_results)\n",
        "\n",
        "    # limpa memória\n",
        "    del df_train, df_test, X_train,  X_submit, X_test, y_train, y_test\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjrES6LM7buH"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbVoDdaz68mD"
      },
      "outputs": [],
      "source": [
        "# junta predições em um único dataframe\n",
        "print ('Erros de treino:', lista_erros_treino)\n",
        "print ('Erros de teste:', lista_erros_teste)\n",
        "print ('Erro médio de treino:', np.mean(lista_erros_treino))\n",
        "print ('Erro médio de teste:', np.mean(lista_erros_teste))\n",
        "df_submit_prediction = reduce(lambda left, right: pd.merge(left, right,on=['NU_INSCRICAO'], how='inner'), lista_df_submissao)\n",
        "df_submit_prediction.to_csv(path_output_submission, sep=',', index=False)\n",
        "print (df_submit_prediction.shape)\n",
        "df_submit_prediction.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO0CpYZO6_S2"
      },
      "source": [
        "Erro de Treino: 78,9\n",
        "\n",
        "Erro de Teste (hold out): 79,2\n",
        "\n",
        "Erro de Teste (Leaderboard pública): 79,2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo finalista"
      ],
      "metadata": {
        "id": "7thN-2_KDu_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_df_submissao = []\n",
        "lista_erros_treino = []\n",
        "lista_erros_teste = []\n",
        "\n",
        "for status, target in zip(lista_status, lista_targets):\n",
        "    print ('*****************')\n",
        "    print (status, target)\n",
        "    print ('*****************')\n",
        "\n",
        "    # variaveis para usar no modelo\n",
        "    lista_vars_modelo = list(set(lista_vars_explicativas) - set([status]))\n",
        "\n",
        "    # variáveis categóricas do modelo\n",
        "    cat_cols = list(set(lista_vars_modelo) - set(lista_vars_numericas))\n",
        "\n",
        "    df_desenv_modelar = df_desenv.query(f\"{status} == 1\")\n",
        "    print (df_desenv.shape, df_desenv_modelar.shape)\n",
        "\n",
        "    df_submit_modelar = df_submit.query(f\"{status} == 1\")\n",
        "    df_submit_remover = df_submit.query(f\"{status} != 1\")[['NU_INSCRICAO']]\n",
        "    df_submit_remover[target] = 0\n",
        "    print (df_submit.shape, df_submit_modelar.shape, df_submit_remover.shape)\n",
        "\n",
        "    # Separa dados em treino e teste\n",
        "    df_train, df_test = train_test_split(df_desenv_modelar, test_size=0.2, random_state=42)\n",
        "\n",
        "    X_train = df_train[lista_vars_modelo].copy()\n",
        "    y_train = df_train[target].copy()\n",
        "\n",
        "    X_test = df_test[lista_vars_modelo].copy()\n",
        "    y_test = df_test[target].copy()\n",
        "\n",
        "    X_submit = df_submit_modelar[lista_vars_modelo].copy()\n",
        "\n",
        "    print (X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_submit.shape)\n",
        "\n",
        "    # converte variáveis categóricas\n",
        "    mapeamento = {}\n",
        "    for col in cat_cols:\n",
        "        ce = CatEncoder()\n",
        "        #print (f'Criando mapeamento para coluna {col}')\n",
        "        ce.fit(X_train[col].astype(str))\n",
        "        mapeamento[col] = ce\n",
        "\n",
        "    for col in cat_cols:\n",
        "        ce = mapeamento[col]\n",
        "        X_train[col] = ce.transform(X_train[col].astype(str))\n",
        "        X_test[col] = ce.transform(X_test[col].astype(str))\n",
        "        X_submit[col] = ce.transform(X_submit[col].astype(str))\n",
        "\n",
        "\n",
        "    ############\n",
        "    # CatBoost #\n",
        "    ############\n",
        "\n",
        "    pool_train = Pool(X_train, y_train, cat_features=cat_cols)\n",
        "    pool_test = Pool(X_test, cat_features=cat_cols)\n",
        "    pool_submit = Pool(X_submit, cat_features=cat_cols)\n",
        "\n",
        "    clf = CatBoostRegressor(iterations=3000,\n",
        "                            learning_rate=0.1,\n",
        "                            loss_function='RMSE',\n",
        "                            depth=8,\n",
        "                            l2_leaf_reg=1000,\n",
        "                            border_count=2000,\n",
        "                            task_type=\"GPU\",\n",
        "                            devices='0:1')\n",
        "\n",
        "    clf.fit(pool_train)\n",
        "\n",
        "    # importâncias\n",
        "    df_importancias = pd.DataFrame(sorted(list(zip(clf.feature_importances_, X_train.columns)), reverse=True))\n",
        "    df_importancias.columns = ['importancia', 'feature']\n",
        "    print (df_importancias['feature'].values.tolist())\n",
        "\n",
        "    # Erro de treino\n",
        "    y_pred = clf.predict(pool_train)\n",
        "    erro = rmse_score(y_train, y_pred)\n",
        "    print ('Erro de treino:', erro)\n",
        "    lista_erros_treino.append(erro)\n",
        "\n",
        "    # Erro de teste\n",
        "    y_pred = clf.predict(pool_test)\n",
        "    erro = rmse_score(y_test, y_pred)\n",
        "    print ('Erro de teste:', erro)\n",
        "    lista_erros_teste.append(erro)\n",
        "\n",
        "    # Previsão para o dataset de submissão\n",
        "    df_final = df_submit_modelar[['NU_INSCRICAO']]\n",
        "    df_final[target] = clf.predict(pool_submit)\n",
        "    df_final = pd.concat([df_final, df_submit_remover], axis=0)\n",
        "    lista_df_submissao.append(df_final)\n",
        "\n",
        "    # limpa memória\n",
        "    del df_submit_modelar, df_submit_remover, df_train, df_test, X_train, y_train, X_test, y_test, X_submit\n",
        "    gc.collect()\n",
        "\n",
        "# junta predições em um único dataframe\n",
        "print ('Erros de treino:', lista_erros_treino)\n",
        "print ('Erros de teste:', lista_erros_teste)\n",
        "print ('Erro médio de treino:', np.mean(lista_erros_treino))\n",
        "print ('Erro médio de teste:', np.mean(lista_erros_teste))\n",
        "df_submit_prediction = reduce(lambda left, right: pd.merge(left, right,on=['NU_INSCRICAO'], how='inner'), lista_df_submissao)\n",
        "df_submit_prediction.to_csv('/content/gdrive/MyDrive/ML_Olympiad_Kaggle/df_submit_novos2.csv', sep=',', index=False)\n",
        "print (df_submit_prediction.shape)\n",
        "df_submit_prediction.head()"
      ],
      "metadata": {
        "id": "781dQSGvDvJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sEIa8SJdDvLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}