{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo: Analise de sentimentos com redes neurais (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    # Positive Reviews\n",
    "    'This is an excellent movie',\n",
    "    'The move was fantastic I like it',\n",
    "    'You should watch it is brilliant',\n",
    "    'Exceptionally good',\n",
    "    'Wonderfully directed and executed I like it',\n",
    "    'Its a fantastic series',\n",
    "    'Never watched such a brillent movie',\n",
    "    'It is a Wonderful movie',\n",
    "\n",
    "    # Negtive Reviews\n",
    "    \"horrible acting\",\n",
    "    'waste of money',\n",
    "    'pathetic picture',\n",
    "    'It was very boring',\n",
    "    'I did not like the movie',\n",
    "    'The movie was horrible',\n",
    "    'I will not recommend',\n",
    "    'The acting is pathetic'\n",
    "]\n",
    "\n",
    "# labels\n",
    "sentiments = array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "[[22, 7, 5, 41, 47], [40, 40, 20, 36, 18, 40, 49], [46, 11, 47, 49, 7, 14], [33, 19], [23, 34, 29, 45, 18, 40, 49], [30, 15, 36, 48], [11, 8, 35, 15, 18, 47], [49, 7, 15, 25, 47], [4, 10], [14, 15, 29], [31, 1], [49, 20, 30, 9], [18, 34, 16, 40, 40, 47], [40, 47, 20, 4], [18, 43, 16, 35], [40, 10, 7, 31]]\n",
      "[[22  7  5 41 47  0  0]\n",
      " [40 40 20 36 18 40 49]\n",
      " [46 11 47 49  7 14  0]\n",
      " [33 19  0  0  0  0  0]\n",
      " [23 34 29 45 18 40 49]\n",
      " [30 15 36 48  0  0  0]\n",
      " [11  8 35 15 18 47  0]\n",
      " [49  7 15 25 47  0  0]\n",
      " [ 4 10  0  0  0  0  0]\n",
      " [14 15 29  0  0  0  0]\n",
      " [31  1  0  0  0  0  0]\n",
      " [49 20 30  9  0  0  0]\n",
      " [18 34 16 40 40 47  0]\n",
      " [40 47 20  4  0  0  0]\n",
      " [18 43 16 35  0  0  0]\n",
      " [40 10  7 31  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# lista de todas as palavras\n",
    "all_words = []\n",
    "for sent in corpus:\n",
    "    tokenize_word = word_tokenize(sent)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)\n",
    "\n",
    "unique_words = set(all_words)\n",
    "vocab_length = 50\n",
    "print(len(unique_words))\n",
    "\n",
    "embedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n",
    "print(embedded_sentences)\n",
    "\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "\n",
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
    "print(padded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 7, 20)             1000      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 1,141\n",
      "Trainable params: 1,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.3750\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6897 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6863 - acc: 0.6875\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6830 - acc: 0.7500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6797 - acc: 0.8750\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6764 - acc: 0.9375\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6731 - acc: 0.9375\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6698 - acc: 0.9375\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6665 - acc: 0.9375\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6632 - acc: 0.9375\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6600 - acc: 0.9375\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6567 - acc: 0.9375\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6533 - acc: 0.9375\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6500 - acc: 0.9375\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6467 - acc: 0.9375\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6433 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6399 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6365 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6331 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6296 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6261 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6226 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6190 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6154 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6118 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6081 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6044 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6006 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5968 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5930 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.5891 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 530us/step - loss: 0.5852 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 416us/step - loss: 0.5812 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5772 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 821us/step - loss: 0.5731 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5690 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5649 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5607 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5565 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5522 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5479 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5436 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5392 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5348 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5303 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5258 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5213 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5167 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5121 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5075 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5028 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4981 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4934 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4887 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4839 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4791 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4743 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4695 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4647 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4598 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4550 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4501 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4452 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4403 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4354 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4305 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4256 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4207 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4158 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4109 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4060 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4011 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3963 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3914 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.3866 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3817 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3769 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3721 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3674 - acc: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.3626 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.3579 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3532 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3485 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3439 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3393 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3347 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3301 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3256 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3211 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3167 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3122 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3079 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3035 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2992 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2949 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2907 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2865 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2824 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2783 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2742 - acc: 1.0000\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_length, 20, input_length=length_long_sentence))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(padded_sentences, sentiments, epochs=100, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(padded_sentences, sentiments, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7, 100)            5000      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 701       \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 701\n",
      "Non-trainable params: 5,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6701 - acc: 0.5625\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6475 - acc: 0.5625\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6256 - acc: 0.5625\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6045 - acc: 0.6875\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5841 - acc: 0.7500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5644 - acc: 0.7500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5455 - acc: 0.7500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5273 - acc: 0.8750\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5099 - acc: 0.8750\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4932 - acc: 0.8750\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4772 - acc: 0.8750\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4619 - acc: 0.8750\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4472 - acc: 0.8750\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4332 - acc: 0.9375\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4198 - acc: 0.9375\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4070 - acc: 0.9375\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3948 - acc: 0.9375\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3831 - acc: 0.9375\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3719 - acc: 0.9375\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3611 - acc: 0.9375\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3509 - acc: 0.9375\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3411 - acc: 0.9375\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3317 - acc: 0.9375\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3227 - acc: 0.9375\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3140 - acc: 0.9375\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3057 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2977 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2901 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2827 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2757 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 972us/step - loss: 0.2689 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 964us/step - loss: 0.2623 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2560 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2499 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2441 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2384 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2330 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2277 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2226 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2177 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2129 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.2084 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2039 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1996 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1955 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1914 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1876 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1838 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1801 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1766 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1731 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.1698 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1666 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1634 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1604 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1574 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1545 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1517 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1490 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1438 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1413 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1389 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1365 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1342 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1320 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1298 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1277 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1256 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1236 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.1216 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1197 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1178 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1160 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1142 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1125 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1075 - acc: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1015 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1000 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0973 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.0959 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0946 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0933 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.0921 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0908 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0896 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0873 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0862 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0829 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 1.0000\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('data/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()\n",
    "\n",
    "\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(padded_sentences, sentiments, epochs=100, verbose=1)\n",
    "loss, accuracy = model.evaluate(padded_sentences, sentiments, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
