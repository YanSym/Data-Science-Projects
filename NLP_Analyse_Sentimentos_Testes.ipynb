{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Natural Language Processing\n",
    "### Analise de sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/960/0*xLRsbQ02J7sQpNNy\" width=400 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "<ipython-input-1-918218091cb8>:27: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import sample\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Embedding\n",
    "from tensorflow.keras.layers import Flatten, Conv1D, GlobalMaxPooling1D, LSTM, SimpleRNN, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "#from kerastuner.tuners import BayesianOptimization\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "list_stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "# plot resultados\n",
    "def plot_results(history):\n",
    "    # acuracia\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# pre-processamento\n",
    "def preprocess_text(sen):\n",
    "    \n",
    "    # Removing html tags\n",
    "    sentence = TAG_RE.sub('', sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # lowercase\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # remove stopwords\n",
    "    #sentence = [w for w in sentence if w not in list_stop_words]\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(50000, 2)\n",
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>Trio's vignettes were insightful and quite enj...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47326</th>\n",
       "      <td>I had never heard of this one before the owner...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48869</th>\n",
       "      <td>This is an excellent but hard to find trippy W...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48623</th>\n",
       "      <td>I am a huge fan of big, loud, trashy, complete...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>Easily Lucio Fulci's most respected film, \"Don...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "3055   Trio's vignettes were insightful and quite enj...  positive\n",
       "47326  I had never heard of this one before the owner...  negative\n",
       "48869  This is an excellent but hard to find trippy W...  positive\n",
       "48623  I am a huge fan of big, loud, trashy, complete...  positive\n",
       "39657  Easily Lucio Fulci's most respected film, \"Don...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv(\"data/IMDB Dataset.csv\")\n",
    "print (movie_reviews.isnull().values.any())\n",
    "print (movie_reviews.shape)\n",
    "\n",
    "# amostra\n",
    "movie_reviews, _ = train_test_split(movie_reviews, train_size=0.5, random_state=42, stratify=movie_reviews['sentiment'])\n",
    "print (movie_reviews.shape)\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    12500\n",
      "positive    12500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x201d73324f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (movie_reviews['sentiment'].value_counts(dropna=False))\n",
    "sns.countplot(x='sentiment', data=movie_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "    \n",
    "y = movie_reviews['sentiment']\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separa dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_val_tmp, X_test_tmp, y_val_tmp, y_test_tmp = train_test_split(X_test, y_test, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_val_tmp = tokenizer.texts_to_sequences(X_val_tmp)\n",
    "X_test_tmp = tokenizer.texts_to_sequences(X_test_tmp)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "X_val_tmp = pad_sequences(X_val_tmp, padding='post', maxlen=maxlen)\n",
    "X_test_tmp = pad_sequences(X_test_tmp, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos com Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/j5Dj80T/bad.png\" width=400 height=400/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_str = []\n",
    "for lista in X_train:\n",
    "    lista = ' '.join([str(x) for x in lista])\n",
    "    X_train_str.append(lista)\n",
    "    \n",
    "X_test_str = []\n",
    "for lista in X_test:\n",
    "    lista = ' '.join([str(x) for x in lista])\n",
    "    X_test_str.append(lista)\n",
    "    \n",
    "CountVec = CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "#transform train\n",
    "Count_data_train = CountVec.fit_transform(X_train_str)\n",
    " \n",
    "#create dataframe\n",
    "df_train_str=pd.DataFrame(Count_data_train.toarray(), columns=CountVec.get_feature_names())\n",
    "\n",
    "\n",
    "#transform test\n",
    "Count_data_test = CountVec.transform(X_test_str)\n",
    " \n",
    "#create dataframe\n",
    "df_test_str=pd.DataFrame(Count_data_test.toarray(), columns=CountVec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW (Bag of Words) + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)\n",
    "\n",
    "# score medio\n",
    "y_pred = classifier.predict_proba(df_train_str)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_list(list_instances):\n",
    "    \n",
    "    list_scores = []\n",
    "    \n",
    "    for text in list_instances:\n",
    "        instance = tokenizer.texts_to_sequences([text])\n",
    "        instance = pad_sequences(instance, padding='post', maxlen=maxlen)   \n",
    "        instance = ' '.join([str(x) for x in instance])\n",
    "        \n",
    "        #transform test\n",
    "        instance = CountVec.transform([instance])\n",
    "\n",
    "        #create dataframe\n",
    "        instance=pd.DataFrame(instance.toarray(), columns=CountVec.get_feature_names())\n",
    "\n",
    "        score = classifier.predict_proba(instance)[:, 1][0]\n",
    "        print (score)\n",
    "        \n",
    "        if (score >= 0.5):\n",
    "            flag = 'Positivo'\n",
    "        else:\n",
    "            flag = 'Negativo'\n",
    "            \n",
    "        list_scores.append([text, score, flag])\n",
    "        \n",
    "    df = pd.DataFrame(list_scores, columns=['text', 'score', 'rating'])\n",
    "    display(df)\n",
    "        \n",
    "        \n",
    "list_instances = ['The movie was amazing, I loved it, very good',\n",
    "                  'I hate this movie, it is very bad and terrible']\n",
    "# score list\n",
    "score_list(list_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW (Bag of Words) + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW (Bag of Words) + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=5)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos com tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1000/1*KZrjbKHcsWt-zzUj2oRk3w.jpeg\" width=400 height=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ytimg.com/vi/vZAXpvHhQow/maxresdefault.jpg\" width=600 height=60/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_str = []\n",
    "for lista in X_train:\n",
    "    lista = ' '.join([str(x) for x in lista])\n",
    "    X_train_str.append(lista)\n",
    "    \n",
    "X_test_str = []\n",
    "for lista in X_test:\n",
    "    lista = ' '.join([str(x) for x in lista])\n",
    "    X_test_str.append(lista)\n",
    "    \n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#transform train\n",
    "Count_data_train = CountVec.fit_transform(X_train_str)\n",
    " \n",
    "#create dataframe\n",
    "df_train_str=pd.DataFrame(Count_data_train.toarray(), columns=CountVec.get_feature_names())\n",
    "\n",
    "\n",
    "#transform test\n",
    "Count_data_test = CountVec.transform(X_test_str)\n",
    " \n",
    "#create dataframe\n",
    "df_test_str=pd.DataFrame(Count_data_test.toarray(), columns=CountVec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Random Forest (max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=3)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Random Forest (max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=5)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Random Forest (max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=7)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf (Bag of Words) + Random Forest (max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=15)\n",
    "classifier.fit(df_train_str, y_train)\n",
    "score_train = round(classifier.score(df_train_str, y_train), 4)\n",
    "score_test = round(classifier.score(df_test_str, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos com Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score_train = round(classifier.score(X_train, y_train), 4)\n",
    "score_test = round(classifier.score(X_test, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "score_train = round(classifier.score(X_train, y_train), 4)\n",
    "score_test = round(classifier.score(X_test, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "score_train = round(classifier.score(X_train, y_train), 4)\n",
    "score_test = round(classifier.score(X_test, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "score_train = round(classifier.score(X_train, y_train), 4)\n",
    "score_test = round(classifier.score(X_test, y_test), 4)\n",
    "\n",
    "# results\n",
    "print(\"Train Accuracy:\", score_train)\n",
    "print(\"Test Accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo simples com Redes Neurais v1 (sem Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=1, validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo simples com Redes Neurais  (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', mode='min', patience=5, verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val_tmp, y_val_tmp), batch_size=128, epochs=30, verbose=1, callbacks=[es, mc])\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model Embedding layer (sem Glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, input_length=maxlen)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', mode='min', patience=5, verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, callbacks=[es, mc], validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('data/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model Glove (sem Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model Glove (com Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=30, verbose=1, callbacks=[es, mc], validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=1, validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=30, verbose=1, callbacks=[es, mc], validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=30, verbose=1, callbacks=[es, mc], validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=15, verbose=1, validation_split=0.2)\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=100, verbose=1, callbacks=[es, mc], validation_split=0.2)\n",
    "print(model.summary())\n",
    "\n",
    "# load a saved model (best model)\n",
    "model = load_model('best_model.h5')\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM com Bayesian Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "n_epochs = 10\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "\n",
    "    model.add(LSTM(units=hp.Int('units1',\n",
    "                                min_value=30,\n",
    "                                max_value=100,\n",
    "                                step=20),\n",
    "              \n",
    "                                dropout=hp.Float('dropout',\n",
    "                                min_value=0.1,\n",
    "                                max_value=0.3,\n",
    "                                step=0.1),\n",
    "    \n",
    "                                recurrent_dropout=hp.Float('recurrent_dropout',\n",
    "                                min_value=0.3,\n",
    "                                max_value=0.6,\n",
    "                                step=0.1), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(units=hp.Int('units2',\n",
    "                                 min_value=30,\n",
    "                                 max_value=100,\n",
    "                                 step=20),\n",
    "                                 activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=['acc'],\n",
    "                  optimizer=keras.optimizers.Adam(\n",
    "                  hp.Choice('learning_rate',\n",
    "                  values=[1e-2, 1e-3, 1e-4])))\n",
    "\n",
    "    return model\n",
    "\n",
    "bayesian_opt_tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='acc',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True)\n",
    "\n",
    "bayesian_opt_tuner.search(X_train, y_train, epochs=n_epochs, validation_split=0.2, verbose=1)\n",
    "\n",
    "bayes_opt_model_best_model = bayesian_opt_tuner.get_best_models(num_models=1)\n",
    "model = bayes_opt_model_best_model[0]\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, validation_split=0.2, epochs=40, verbose=1)\n",
    "\n",
    "print(model.summary())\n",
    "score_train = model.evaluate(X_train, y_train, verbose=1)\n",
    "score_test = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# results\n",
    "print (\"Train Accuracy:\", score_train[1])\n",
    "print(\"Test Accuracy:\", score_test[1])\n",
    "plot_results(history)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance = sample(X, 1)\n",
    "print (instance)\n",
    "instance = tokenizer.texts_to_sequences(instance)\n",
    "\n",
    "instance = pad_sequences(instance, padding='post', maxlen=maxlen)\n",
    "print (instance)\n",
    "\n",
    "score = model.predict(instance)[0][0]\n",
    "print (score)\n",
    "if (score >= 0.5):\n",
    "    print ('Positivo')\n",
    "else:\n",
    "    print ('Negativo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction (tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_list(list_instances):\n",
    "    \n",
    "    list_scores = []\n",
    "    \n",
    "    for text in list_instances:\n",
    "        instance = tokenizer.texts_to_sequences([text])\n",
    "        instance = pad_sequences(instance, padding='post', maxlen=maxlen)\n",
    "\n",
    "        score = model.predict(instance)[0][0]\n",
    "        \n",
    "        if (score >= 0.5):\n",
    "            flag = 'Positivo'\n",
    "        else:\n",
    "            flag = 'Negativo'\n",
    "            \n",
    "        list_scores.append([text, score, flag])\n",
    "        \n",
    "    df = pd.DataFrame(list_scores, columns=['text', 'score', 'rating'])\n",
    "    display(df)\n",
    "        \n",
    "        \n",
    "list_instances = ['The movie was amazing, I loved it, very good',\n",
    "                  'I hate this movie, it is very bad and terrible']\n",
    "\n",
    "# score list\n",
    "score_list(list_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                      text_a = x[DATA_COLUMN], \n",
    "                                      text_b = None,\n",
    "                                      label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                      text_a = x[DATA_COLUMN], \n",
    "                                      text_b = None,\n",
    "                                      label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    return train_InputExamples, validation_InputExamples\n",
    "    \n",
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            padding=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "        input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanvs\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame({'sentiment':X_train, 'review':y_train})\n",
    "test = pd.DataFrame({'sentiment':X_test, 'review':y_test})\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'sentiment'\n",
    "LABEL_COLUMN = 'review'\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
    "                                                                         test, \n",
    "                                                                         DATA_COLUMN, \n",
    "                                                                         LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000201D72C5B20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000201D72C5B20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "      6/Unknown - 630s 105s/step - loss: 0.6843 - accuracy: 0.6042"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = ['This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good',\n",
    "                  'One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "labels = ['Negative','Positive']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(pred_sentences)):\n",
    "    print(pred_sentences[i], \": \\n\", labels[label[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
